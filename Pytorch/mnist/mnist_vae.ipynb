{
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "k7PS0uYOHY"
      },
      "source": [
        "from keras.datasets import mnist\n",
        "\n",
        "(train_ims, train_labs), (test_ims, test_labs) = mnist.load_data()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "8O1yEnaEck"
      },
      "source": [
        "from mnist import MNIST\n",
        "\n",
        "data = MNIST('/Users/nickeisenberg/GitRepos/DataSets_local/MNIST/imgs')\n",
        "train_ims_, train_labs = data.load_training()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "HwMJ9yB9AX"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.functional as F\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import random"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "uqWwStcYEn"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "p2j73JdljP"
      },
      "source": [
        "train_ims = torch.stack([\n",
        "    torch.tensor(\n",
        "        im, dtype=torch.uint8\n",
        "    ).reshape((1, 28, 28)) / 255 for im in train_ims\n",
        "])\n",
        "train_labs = torch.tensor(train_labs)\n",
        "\n",
        "train_ims.size()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "ipMv8PFi0O"
      },
      "source": [
        "class ImageDataset(Dataset):\n",
        "\n",
        "  def __init__(self, X, Y):\n",
        "    self.X = X\n",
        "    self.Y = Y\n",
        "    if len(self.X) != len(self.Y):\n",
        "      raise Exception(\"The length of X does not match the length of Y\")\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.X)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    _x = self.X[index]\n",
        "    _y = self.Y[index]\n",
        "\n",
        "    return _x, _y\n",
        "\n",
        "random.seed(1)\n",
        "dataset_inds = np.arange(len(train_ims))\n",
        "random.shuffle(dataset_inds)\n",
        "\n",
        "train_dataset = ImageDataset(\n",
        "    train_ims[dataset_inds[:50000]], train_ims[dataset_inds[:50000]]\n",
        ")\n",
        "\n",
        "val_dataset = ImageDataset(\n",
        "    train_ims[dataset_inds[50000:]], train_ims[dataset_inds[50000:]]\n",
        ")\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, 64)\n",
        "val_dataloader = DataLoader(val_dataset, 64)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "Exb9JYmqm4"
      },
      "source": [
        "latent_dim = 2\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "\n",
        "    def __init__(self, latent_dim):\n",
        "        super().__init__()\n",
        "        self.latent_dim = latent_dim\n",
        "        self.conv1 = nn.Conv2d(\n",
        "            in_channels=1,\n",
        "            out_channels=32,\n",
        "            kernel_size=3,\n",
        "            stride=2,\n",
        "            padding=1\n",
        "        )\n",
        "        self.conv2 = nn.Conv2d(\n",
        "            in_channels=32,\n",
        "            out_channels=64,\n",
        "            kernel_size=3,\n",
        "            stride=2,\n",
        "            padding=1\n",
        "        )\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.linear1 = nn.Linear(7 * 7 * 64, 16)\n",
        "        self.z_mean_ = nn.Linear(16, latent_dim)\n",
        "        self.z_log_var_ = nn.Linear(16, latent_dim)\n",
        "\n",
        "    def forward(self, input_img):\n",
        "        x = self.conv1(input_img)\n",
        "        x = nn.ReLU()(x)\n",
        "        x = self.conv2(x)\n",
        "        x = nn.ReLU()(x)\n",
        "        x = self.flatten(x)\n",
        "        x = self.linear1(x)\n",
        "        x = nn.ReLU()(x)\n",
        "        z_mean = self.z_mean_(x)\n",
        "        z_log_var = self.z_log_var_(x)\n",
        "        return z_mean, z_log_var\n",
        "\n",
        "class Sampler(nn.Module):\n",
        "\n",
        "    def __init__(self, latent_dim):\n",
        "        self.latent_dim = latent_dim\n",
        "        super().__init__()\n",
        "\n",
        "    def forward(self, z_mean, z_log_var):\n",
        "        batch_size = z_mean.shape[0]\n",
        "        epsilon = torch.randn((batch_size, self.latent_dim))\n",
        "        return z_mean + torch.exp(0.5 * z_log_var) * epsilon\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "\n",
        "    def __init__(self, latent_dim):\n",
        "        super().__init__()\n",
        "        self.latent_dim = latent_dim\n",
        "        self.linear1 = nn.Linear(latent_dim, 16)\n",
        "        self.linear2 = nn.Linear(16, 7 * 7 * 64)\n",
        "        self.convt1 = nn.ConvTranspose2d(\n",
        "            64, 32, kernel_size=3, stride=2, padding=1, output_padding=1\n",
        "        )\n",
        "        self.convt2 = nn.ConvTranspose2d(\n",
        "            32, 1, kernel_size=3, stride=2, padding=1, output_padding=1\n",
        "        )\n",
        "        self.conv1 = nn.Conv2d(\n",
        "            1, 1, kernel_size=3, padding=1\n",
        "        )\n",
        "\n",
        "    def forward(self, latent_input):\n",
        "        x = self.linear1(latent_input)\n",
        "        x = nn.ReLU()(x)\n",
        "        x = self.linear2(x)\n",
        "        x = nn.ReLU()(x)\n",
        "        x = x.reshape(x.shape[0], 7, 7, 64).permute(0, 3, 1, 2)\n",
        "        x = self.convt1(x)\n",
        "        x = nn.ReLU()(x)\n",
        "        x = self.convt2(x)\n",
        "        x = nn.ReLU()(x)\n",
        "        decoded_image = self.conv1(x)\n",
        "        decoded_image = nn.Sigmoid()(decoded_image)\n",
        "        return decoded_image\n",
        "\n",
        "class VAE(nn.Module):\n",
        "\n",
        "    def __init__(self, encoder, sampler, decoder, latent_dim):\n",
        "        super().__init__()\n",
        "        self.latent_dim = latent_dim\n",
        "        self.encoder = Encoder(latent_dim)\n",
        "        self.sampler = Sampler(latent_dim)\n",
        "        self.decoder = Decoder(latent_dim)\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        zmean, zlogvar = self.encoder(inputs)\n",
        "        samps = self.sampler(zmean, zlogvar)\n",
        "        recon = self.decoder(samps)\n",
        "        return recon, (zmean, zlogvar)\n",
        "\n",
        "\n",
        "loss_fn = nn.BCELoss()\n",
        "\n",
        "def kl_regularization(z_mean, z_log_var):\n",
        "    kl_reg = -0.5\n",
        "    kl_reg *= (1 + z_log_var - torch.square(z_mean) - torch.exp(z_log_var))\n",
        "    return torch.sum(kl_reg)\n",
        "\n",
        "# ims = nn.Sigmoid()(torch.randn((4, 1, 28, 28)))\n",
        "# tars = nn.Sigmoid()(torch.randn((4, 1, 28, 28)))\n",
        "# zm = torch.randn((4, 2))\n",
        "# zv = torch.randn((4, 2))\n",
        "# \n",
        "# loss_fn(ims, tars)\n",
        "# kl_regularization(zm, zv)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "yTDNqaKKyM"
      },
      "source": [
        "vae = VAE(Encoder, Sampler, Decoder, latent_dim)\n",
        "optimizer = torch.optim.Adam(vae.parameters(), lr=.001)\n",
        "\n",
        "# im = train_ims[0]\n",
        "# im = im.unsqueeze(0)\n",
        "# im.shape\n",
        "# recon = vae(im)[0][0][0].detach().numpy()\n",
        "# plt.imshow(recon)\n",
        "# plt.show()\n",
        "\n",
        "def train_one_epoch(dataloader):\n",
        "    total_loss = 0.\n",
        "    running_loss = 0.\n",
        "    counter = 1\n",
        "    for i, data in enumerate(dataloader):\n",
        "        counter = i\n",
        "        imgs, _ = data\n",
        "        imgs = imgs.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        recon_imgs, (zmean, zlogvar) = vae(imgs)\n",
        "        recon_loss = loss_fn(recon_imgs, imgs)\n",
        "        kl_loss = kl_regularization(zmean, zlogvar)\n",
        "        loss = recon_loss + kl_loss\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "        running_loss += loss.item()\n",
        "        if i % 80  == 0:\n",
        "            last_loss = running_loss / 80 # loss per batch\n",
        "            print(f'batch {i / 80} loss: {last_loss}')\n",
        "            running_loss = 0.\n",
        "    return total_loss / counter"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "aUGAVHFWXA"
      },
      "source": [
        "        \n",
        "EPOCHS = 2\n",
        "best_vloss = 1e6\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "\n",
        "    print(f'Epoch: {epoch + 1}')\n",
        "\n",
        "    _ = vae.train()\n",
        "    avg_loss = train_one_epoch(dataloader=train_dataloader)\n",
        "\n",
        "    _ = vae.eval()\n",
        "    running_v_loss = 0.0\n",
        "    counter = 1\n",
        "    with torch.no_grad():\n",
        "        for i, v_data in enumerate(val_dataloader):\n",
        "            counter = i\n",
        "            v_ims, _ = v_data\n",
        "            v_ims = v_ims.to(device)\n",
        "            v_guess, (v_zmean, v_zlogvar) = vae(v_ims)\n",
        "            v_loss_recon = loss_fn(v_guess, v_ims)\n",
        "            running_v_loss += v_loss_recon\n",
        "    \n",
        "    avg_vloss = running_v_loss / counter\n",
        "\n",
        "    print(f'LOSS Train: {avg_loss} Val: {avg_vloss}')\n",
        "    \n",
        "    if avg_vloss < best_vloss:\n",
        "        best_vloss = avg_vloss\n",
        "        model_path = '~/GitRepos/Python_Notebook/Pytorch/mnist/mnist_vae.torch'\n",
        "        torch.save(vae.state_dict(), model_path)\n",
        "\n",
        "im = train_ims[0].unsqueeze(0)\n",
        "recon = vae(im)[0].detach().numpy()\n",
        "\n",
        "fig, ax = plt.subplots(1, 2)\n",
        "ax[0].imshow(im[0][0])\n",
        "ax[1].imshow(recon[0][0])\n",
        "plt.show()"
      ],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "python",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}